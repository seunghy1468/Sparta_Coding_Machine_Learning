{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework 1 week.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHmUks//Gr0TOaeEIBYW5F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunghy1468/Sparta_Coding_Machine_Learning/blob/main/homework_1_week.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLUnihKMfE1X"
      },
      "source": [
        "# linear regression 구현 (1 week)\n",
        "# 연차로부터 연봉예측하기\n",
        "# learning rate(lr)를 바꾸면서 실험하기\n",
        "# Optimizer를 바꾸면서 실험하기\n",
        "# loss fuction을 mean_absolute_error로 바꿔서 실험하기"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM63mGeDgolX",
        "outputId": "aedcc98b-60dd-439c-ee8f-6357baee07f6"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = '' # username\n",
        "os.environ['KAGGLE_KEY'] = '' # key\n",
        "\n",
        "!kaggle datasets download -d rohankayan/years-of-experience-and-salary-dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading years-of-experience-and-salary-dataset.zip to /content\n",
            "\r  0% 0.00/378 [00:00<?, ?B/s]\n",
            "\r100% 378/378 [00:00<00:00, 333kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkO49a1ygpJr",
        "outputId": "f48c75b9-a3d6-42a2-8623-d8fb673de19a"
      },
      "source": [
        "!unzip /content/years-of-experience-and-salary-dataset.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/years-of-experience-and-salary-dataset.zip\n",
            "  inflating: Salary_Data.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "7FqqFnxahb65",
        "outputId": "47d7ec0f-af83-4d62-928d-520e429c878a"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "salary_data = pd.read_csv('Salary_Data.csv')\n",
        "salary_data.tail(5)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YearsExperience</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>9.0</td>\n",
              "      <td>105582.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>9.5</td>\n",
              "      <td>116969.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>9.6</td>\n",
              "      <td>112635.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>10.3</td>\n",
              "      <td>122391.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>10.5</td>\n",
              "      <td>121872.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    YearsExperience    Salary\n",
              "25              9.0  105582.0\n",
              "26              9.5  116969.0\n",
              "27              9.6  112635.0\n",
              "28             10.3  122391.0\n",
              "29             10.5  121872.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_fkEl3EhuGm",
        "outputId": "d04cbd96-cd88-4fe2-efae-e37e8216b579"
      },
      "source": [
        "salary_data.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "Mg5tpT2WiAM8",
        "outputId": "770afb6b-0ce8-47c6-a380-ee67d6a636f3"
      },
      "source": [
        "sns.pairplot(salary_data, x_vars=['YearsExperience'], y_vars=['Salary'], height=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.PairGrid at 0x7f5a4cd44bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JGesrxciOzu",
        "outputId": "cf02c3aa-a8ea-4a96-f429-319285002455"
      },
      "source": [
        "x_data = np.array(salary_data['YearsExperience'], dtype=np.float32)\n",
        "y_data = np.array(salary_data['Salary'], dtype=np.float32)\n",
        "\n",
        "print(x_data.shape)\n",
        "print(y_data.shape)\n",
        "\n",
        "x_data = x_data.reshape((-1, 1))\n",
        "y_data = y_data.reshape((-1, 1))\n",
        "\n",
        "print(x_data.shape)\n",
        "print(y_data.shape)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=2021)\n",
        "print(x_train.shape, x_val.shape)\n",
        "print(y_train.shape, y_val.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30,)\n",
            "(30,)\n",
            "(30, 1)\n",
            "(30, 1)\n",
            "(24, 1) (6, 1)\n",
            "(24, 1) (6, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE4xwTCWjEKy",
        "outputId": "3b460acc-a423-48cf-c7a7-e4e469524d04"
      },
      "source": [
        "model = Sequential([\n",
        "  Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss='mean_absolute_error', optimizer=Adam(lr=20))\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data=(x_val, y_val), \n",
        "    # 검증 데이터를 넣어주면 한 epoch이 끝날때마다 자동으로 검증된 결과를 보여준다.\n",
        "    epochs=1000 # epochs 복수형으로 쓰기!\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 79737.2422 - val_loss: 61010.2500\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 79604.3203 - val_loss: 60910.5820\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 79471.4062 - val_loss: 60810.9180\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 79338.4922 - val_loss: 60711.2500\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 79205.5703 - val_loss: 60611.5820\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 79072.6641 - val_loss: 60511.9180\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 78939.7422 - val_loss: 60412.2500\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 78806.8281 - val_loss: 60312.5820\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 78673.9141 - val_loss: 60212.9180\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 78540.9922 - val_loss: 60113.2500\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 78408.0781 - val_loss: 60013.5820\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 78275.1641 - val_loss: 59913.9180\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 78142.2422 - val_loss: 59814.2500\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 78009.3281 - val_loss: 59714.5820\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 77876.4141 - val_loss: 59614.9180\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 77743.4922 - val_loss: 59515.2500\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 77610.5859 - val_loss: 59415.5820\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 77477.6641 - val_loss: 59315.9180\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 77344.7422 - val_loss: 59216.2500\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 77211.8359 - val_loss: 59116.5820\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 77078.9141 - val_loss: 59016.9180\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 76945.9922 - val_loss: 58917.2500\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 76813.0703 - val_loss: 58817.5820\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 76680.1641 - val_loss: 58717.9180\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 76547.2422 - val_loss: 58618.2500\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 76414.3281 - val_loss: 58518.5820\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 76281.4141 - val_loss: 58418.9180\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 76148.4922 - val_loss: 58319.2500\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 76015.5781 - val_loss: 58219.5820\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 75882.6641 - val_loss: 58119.9180\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 75749.7422 - val_loss: 58020.2500\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 75616.8281 - val_loss: 57920.5820\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 75483.9141 - val_loss: 57820.9180\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 75350.9922 - val_loss: 57721.2500\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 75218.0859 - val_loss: 57621.5820\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 75085.1641 - val_loss: 57521.9180\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 74952.2422 - val_loss: 57422.2500\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 74819.3203 - val_loss: 57322.5820\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 74686.4141 - val_loss: 57222.9180\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 74553.5000 - val_loss: 57123.2500\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 74420.5703 - val_loss: 57023.5820\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 74287.6641 - val_loss: 56923.9180\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 74154.7500 - val_loss: 56824.2500\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 74021.8359 - val_loss: 56724.5820\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 73888.9141 - val_loss: 56624.9180\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 73755.9922 - val_loss: 56525.2500\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 73623.0781 - val_loss: 56425.5820\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 73490.1641 - val_loss: 56325.9180\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 73357.2500 - val_loss: 56226.2500\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 73224.3281 - val_loss: 56126.5820\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 73091.4141 - val_loss: 56026.9180\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 72958.4922 - val_loss: 55927.2500\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 72825.5781 - val_loss: 55827.5820\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 72692.6641 - val_loss: 55727.9180\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 72559.7500 - val_loss: 55628.2500\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 72426.8359 - val_loss: 55528.5820\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 72293.9141 - val_loss: 55428.9180\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 72160.9922 - val_loss: 55329.2500\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 72028.0781 - val_loss: 55229.5820\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 71895.1641 - val_loss: 55129.9180\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 71762.2422 - val_loss: 55030.2500\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 71629.3281 - val_loss: 54930.5820\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 71496.4141 - val_loss: 54830.9180\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 71363.5000 - val_loss: 54731.2500\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 71230.5859 - val_loss: 54631.5820\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 71097.6641 - val_loss: 54531.9180\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 70964.7422 - val_loss: 54432.2500\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 70831.8281 - val_loss: 54332.5820\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 70698.9141 - val_loss: 54232.9180\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 70565.9922 - val_loss: 54133.2500\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 70433.0781 - val_loss: 54033.5820\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 70300.1641 - val_loss: 53933.9180\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 70167.2422 - val_loss: 53834.2500\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 70034.3359 - val_loss: 53734.5820\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 69901.4141 - val_loss: 53634.9180\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 69768.4922 - val_loss: 53535.2500\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 69635.5859 - val_loss: 53435.5820\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 69502.6641 - val_loss: 53335.9180\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 69369.7500 - val_loss: 53236.2500\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 69236.8281 - val_loss: 53136.5820\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 69103.9141 - val_loss: 53036.9180\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 68971.0000 - val_loss: 52937.2500\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 68838.0781 - val_loss: 52837.5820\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 68705.1641 - val_loss: 52737.9180\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 68572.2422 - val_loss: 52638.2500\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 68439.3281 - val_loss: 52538.5820\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 68306.4141 - val_loss: 52438.9180\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 68173.4922 - val_loss: 52339.2500\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 68040.5859 - val_loss: 52239.5820\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 67907.6641 - val_loss: 52139.9180\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 67774.7422 - val_loss: 52040.2500\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 67641.8281 - val_loss: 51940.5820\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 67508.9141 - val_loss: 51840.9180\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 67375.9922 - val_loss: 51741.2500\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 67243.0781 - val_loss: 51641.5820\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 67110.1641 - val_loss: 51541.9180\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 66977.2422 - val_loss: 51442.2500\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 66844.3359 - val_loss: 51342.5820\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 66711.4141 - val_loss: 51242.9180\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 66578.5000 - val_loss: 51143.2500\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 66445.5781 - val_loss: 51043.5820\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 66312.6641 - val_loss: 50943.9180\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 66179.7422 - val_loss: 50844.2500\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 66046.8359 - val_loss: 50744.5820\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 65913.9141 - val_loss: 50644.9180\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 65781.0000 - val_loss: 50545.2500\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 65648.0781 - val_loss: 50445.5820\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 65515.1602 - val_loss: 50345.9180\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 65382.2461 - val_loss: 50246.2500\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 65249.3281 - val_loss: 50146.5820\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 65116.4102 - val_loss: 50046.9180\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 64983.4961 - val_loss: 49947.2500\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 64850.5781 - val_loss: 49847.5820\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 64717.6602 - val_loss: 49747.9180\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 64584.7461 - val_loss: 49648.2500\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 64451.8281 - val_loss: 49548.5820\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 64318.9102 - val_loss: 49448.9180\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 64185.9883 - val_loss: 49349.2500\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 64053.0820 - val_loss: 49249.5820\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 63920.1602 - val_loss: 49149.9180\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 63787.2461 - val_loss: 49050.2500\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 63654.3320 - val_loss: 48950.5820\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 63521.4102 - val_loss: 48850.9180\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 63388.5000 - val_loss: 48751.2500\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 63255.5781 - val_loss: 48651.5820\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 63122.6602 - val_loss: 48551.9180\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 62989.7461 - val_loss: 48452.2500\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 62856.8281 - val_loss: 48352.5820\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 62723.9102 - val_loss: 48252.9180\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 62590.9961 - val_loss: 48153.2500\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 62458.0781 - val_loss: 48053.5820\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 62325.1602 - val_loss: 47953.9180\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 62192.2383 - val_loss: 47854.2500\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 62059.3242 - val_loss: 47754.5820\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 61926.4180 - val_loss: 47654.9180\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 61793.4961 - val_loss: 47555.2500\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 61660.5781 - val_loss: 47455.5820\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 61527.6680 - val_loss: 47355.9180\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 61394.7500 - val_loss: 47256.2500\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 61261.8320 - val_loss: 47156.5820\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 61128.9102 - val_loss: 47056.9180\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 60995.9961 - val_loss: 46957.2500\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 60863.0781 - val_loss: 46857.5820\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 60730.1602 - val_loss: 46757.9180\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 60597.2461 - val_loss: 46658.2500\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 60464.3281 - val_loss: 46558.5820\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 60331.4102 - val_loss: 46458.9180\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 60198.5000 - val_loss: 46359.2500\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 60065.5781 - val_loss: 46259.5820\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 59932.6602 - val_loss: 46159.9180\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 59799.7500 - val_loss: 46060.2500\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 59666.8320 - val_loss: 45960.5820\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 59533.9062 - val_loss: 45860.9180\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 59400.9961 - val_loss: 45761.2500\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 59268.0820 - val_loss: 45661.5820\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 59135.1680 - val_loss: 45561.9180\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 59002.2461 - val_loss: 45462.2500\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 58869.3281 - val_loss: 45362.5820\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 58736.4180 - val_loss: 45262.9180\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 58603.4961 - val_loss: 45163.2500\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 58470.5781 - val_loss: 45063.5820\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 58337.6602 - val_loss: 44963.9180\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 58204.7383 - val_loss: 44864.2500\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 58071.8242 - val_loss: 44764.5820\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 57938.9062 - val_loss: 44664.9180\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 57805.9961 - val_loss: 44565.2500\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 57673.0820 - val_loss: 44465.5820\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 57540.1602 - val_loss: 44365.9180\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 57407.2461 - val_loss: 44266.2500\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 57274.3281 - val_loss: 44166.5820\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 57141.4102 - val_loss: 44066.9180\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 57008.4961 - val_loss: 43967.2500\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 56875.5781 - val_loss: 43867.5820\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 56742.6602 - val_loss: 43767.9180\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 56609.7461 - val_loss: 43668.2500\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 56476.8281 - val_loss: 43568.5820\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 56343.9102 - val_loss: 43468.9180\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 56210.9961 - val_loss: 43369.2500\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 56078.0781 - val_loss: 43269.5820\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 55945.1602 - val_loss: 43169.9180\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 55812.2461 - val_loss: 43070.2500\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 55679.3281 - val_loss: 42970.5820\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 55546.4062 - val_loss: 42870.9180\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 55413.4883 - val_loss: 42771.2500\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 55280.5781 - val_loss: 42671.5820\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 55147.6602 - val_loss: 42571.9180\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 55014.7461 - val_loss: 42472.2500\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 54881.8281 - val_loss: 42372.5820\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 54748.9062 - val_loss: 42272.9180\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 54615.9961 - val_loss: 42173.2500\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 54483.0781 - val_loss: 42073.5820\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 54350.1562 - val_loss: 41973.9180\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 54217.2461 - val_loss: 41874.2500\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 54084.3242 - val_loss: 41774.5820\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 53951.4102 - val_loss: 41674.9180\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 53818.4961 - val_loss: 41575.2500\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 53685.5742 - val_loss: 41475.5820\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 53552.6602 - val_loss: 41375.9180\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 53419.7500 - val_loss: 41276.2500\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 53286.8281 - val_loss: 41176.5820\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 53153.9102 - val_loss: 41076.9180\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 53020.9961 - val_loss: 40977.2500\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 52888.0781 - val_loss: 40877.5820\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 52755.1602 - val_loss: 40777.9180\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 52622.2461 - val_loss: 40678.2500\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 52489.3320 - val_loss: 40578.5820\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 52356.4180 - val_loss: 40478.9180\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 52223.4883 - val_loss: 40379.2500\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 52090.5820 - val_loss: 40279.5820\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 51957.6680 - val_loss: 40179.9180\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 51824.7500 - val_loss: 40080.2500\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 51691.8281 - val_loss: 39980.5820\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 51558.9102 - val_loss: 39880.9180\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 51426.0000 - val_loss: 39781.2500\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 51293.0781 - val_loss: 39681.5820\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 51160.1680 - val_loss: 39581.9180\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 51027.2461 - val_loss: 39482.2500\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 50894.3281 - val_loss: 39382.5820\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 50761.4102 - val_loss: 39282.9180\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 50628.4961 - val_loss: 39183.2500\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 50495.5820 - val_loss: 39083.5820\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 50362.6602 - val_loss: 38983.9180\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 50229.7461 - val_loss: 38884.2500\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 50096.8281 - val_loss: 38784.5820\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 49963.9102 - val_loss: 38684.9180\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 49830.9961 - val_loss: 38585.2500\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 49698.0820 - val_loss: 38485.5820\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 49565.1602 - val_loss: 38385.9180\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 49432.2383 - val_loss: 38286.2500\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 49299.3281 - val_loss: 38186.5820\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 49166.4102 - val_loss: 38086.9180\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 49033.5000 - val_loss: 37987.2500\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 48900.5781 - val_loss: 37887.5820\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 48767.6680 - val_loss: 37787.9180\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 48634.7461 - val_loss: 37688.2500\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 48501.8320 - val_loss: 37588.5820\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 48368.9102 - val_loss: 37488.9180\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 48236.0000 - val_loss: 37389.2500\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 48103.0781 - val_loss: 37289.5820\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 47970.1680 - val_loss: 37189.9180\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 47837.2500 - val_loss: 37090.2500\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 47704.3281 - val_loss: 36990.5820\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 47571.4102 - val_loss: 36890.9180\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 47438.5000 - val_loss: 36791.2500\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 47305.5781 - val_loss: 36691.5820\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 47172.6680 - val_loss: 36591.9180\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 47039.7461 - val_loss: 36492.2500\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 46906.8320 - val_loss: 36392.5820\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 46773.9180 - val_loss: 36292.9180\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 46640.9961 - val_loss: 36193.2500\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 46508.0781 - val_loss: 36093.5820\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 46375.1680 - val_loss: 35993.9180\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 46242.2461 - val_loss: 35894.2500\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 46109.3281 - val_loss: 35794.5820\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 45976.4102 - val_loss: 35694.9180\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 45843.5000 - val_loss: 35595.2500\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 45710.5820 - val_loss: 35495.5820\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 45577.6602 - val_loss: 35395.9180\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 45444.7500 - val_loss: 35296.2500\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 45311.8320 - val_loss: 35196.5820\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 45178.9180 - val_loss: 35096.9180\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 45046.0000 - val_loss: 34997.2500\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 44913.0820 - val_loss: 34897.5820\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 44780.1602 - val_loss: 34797.9180\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 44647.2461 - val_loss: 34698.2500\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 44514.3281 - val_loss: 34598.5820\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 44381.4102 - val_loss: 34498.9180\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 44248.4961 - val_loss: 34399.2500\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 44115.5781 - val_loss: 34299.5820\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 43982.6680 - val_loss: 34199.9180\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 43849.7500 - val_loss: 34100.2500\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 43716.8281 - val_loss: 34000.5820\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 43583.9102 - val_loss: 33900.9180\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 43450.9961 - val_loss: 33801.2500\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 43318.0781 - val_loss: 33701.5820\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 43185.1602 - val_loss: 33601.9180\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 43052.2461 - val_loss: 33502.2500\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 42919.3281 - val_loss: 33402.5820\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 42786.4102 - val_loss: 33302.9180\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 42653.4961 - val_loss: 33203.2500\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 42520.5781 - val_loss: 33103.5820\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 42387.6602 - val_loss: 33003.9180\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 42254.7461 - val_loss: 32904.2500\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 42121.8281 - val_loss: 32804.5820\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 41988.9102 - val_loss: 32704.9160\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 41855.9961 - val_loss: 32605.2500\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 41723.0781 - val_loss: 32505.5840\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 41590.1602 - val_loss: 32405.9160\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 41457.2461 - val_loss: 32306.2500\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 41324.3281 - val_loss: 32206.5840\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 41191.4102 - val_loss: 32106.9160\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 41058.4961 - val_loss: 32007.2500\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 40925.5781 - val_loss: 31907.5840\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 40792.6602 - val_loss: 31807.9160\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 40659.7461 - val_loss: 31708.2500\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 40526.8320 - val_loss: 31608.5840\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 40393.9102 - val_loss: 31508.9160\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 40260.9961 - val_loss: 31409.2500\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 40128.0781 - val_loss: 31309.5840\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 39995.1602 - val_loss: 31209.9160\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 39862.2461 - val_loss: 31110.2500\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 39729.3320 - val_loss: 31010.5840\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 39596.4141 - val_loss: 30910.9160\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 39463.4961 - val_loss: 30811.2500\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 39330.5781 - val_loss: 30711.5840\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 39197.6602 - val_loss: 30611.9160\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 39064.7461 - val_loss: 30512.2500\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 38931.8281 - val_loss: 30412.5840\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 38798.9102 - val_loss: 30312.9160\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 38665.9961 - val_loss: 30213.2500\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 38533.0781 - val_loss: 30113.5840\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 38400.1641 - val_loss: 30013.9160\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 38267.2461 - val_loss: 29914.2500\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 38134.3281 - val_loss: 29814.5840\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 38001.4102 - val_loss: 29714.9160\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 37868.4961 - val_loss: 29615.2500\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37735.5781 - val_loss: 29515.5840\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37602.6602 - val_loss: 29415.9160\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 37469.7461 - val_loss: 29316.2500\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 37336.8281 - val_loss: 29216.5840\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 37203.9102 - val_loss: 29116.9160\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 37070.9961 - val_loss: 29017.2500\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 36938.0781 - val_loss: 28917.5840\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 36805.1602 - val_loss: 28817.9160\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 36672.2461 - val_loss: 28718.2500\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 36539.3281 - val_loss: 28618.5840\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 36406.4102 - val_loss: 28518.9160\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 36273.4961 - val_loss: 28419.2500\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 36140.5781 - val_loss: 28319.5840\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 36007.6602 - val_loss: 28219.9160\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 35874.7461 - val_loss: 28120.2500\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 35741.8281 - val_loss: 28020.5840\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 35608.9102 - val_loss: 27920.9160\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 35475.9961 - val_loss: 27821.2500\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 35343.0781 - val_loss: 27721.5840\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 35210.1602 - val_loss: 27621.9160\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 35077.2461 - val_loss: 27522.2500\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 34944.3320 - val_loss: 27422.5840\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 34811.4141 - val_loss: 27322.9160\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 34678.4961 - val_loss: 27223.2500\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 34545.5781 - val_loss: 27123.5840\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 34412.6602 - val_loss: 27023.9160\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 34279.7461 - val_loss: 26924.2500\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 34146.8281 - val_loss: 26824.5840\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 34013.9102 - val_loss: 26724.9160\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 33880.9961 - val_loss: 26625.2500\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 33748.0781 - val_loss: 26525.5840\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 33615.1602 - val_loss: 26425.9160\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 33482.2461 - val_loss: 26326.2500\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 33349.3320 - val_loss: 26226.5840\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 33216.4102 - val_loss: 26126.9160\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 33083.4961 - val_loss: 26027.2500\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 32950.5781 - val_loss: 25927.5840\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 32817.6602 - val_loss: 25827.9160\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 32684.7441 - val_loss: 25728.2500\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 32551.8281 - val_loss: 25628.5840\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 32418.9121 - val_loss: 25528.9160\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 32285.9941 - val_loss: 25429.2500\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 32153.0781 - val_loss: 25329.5840\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 32020.1621 - val_loss: 25229.9160\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 31887.2441 - val_loss: 25130.2500\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 31754.3281 - val_loss: 25030.5840\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 31621.4121 - val_loss: 24930.9160\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 31488.4941 - val_loss: 24831.2500\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 31355.5781 - val_loss: 24731.5840\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 31222.6621 - val_loss: 24631.9160\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 31089.7441 - val_loss: 24532.2500\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 30956.8281 - val_loss: 24432.5840\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 30823.9141 - val_loss: 24332.9160\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 30690.9941 - val_loss: 24233.2500\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 30558.0781 - val_loss: 24133.5840\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 30425.1621 - val_loss: 24033.9160\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 30292.2441 - val_loss: 23934.2500\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 30159.3281 - val_loss: 23834.5840\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 30026.4121 - val_loss: 23734.9160\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 29893.4941 - val_loss: 23635.2500\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 29760.5781 - val_loss: 23535.5840\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 29627.6641 - val_loss: 23435.9160\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 29494.7480 - val_loss: 23336.2500\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 29361.8281 - val_loss: 23236.5840\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 29228.9121 - val_loss: 23136.9160\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 29095.9941 - val_loss: 23037.2500\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 28963.0781 - val_loss: 22937.5840\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 28830.1621 - val_loss: 22837.9160\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 28697.2480 - val_loss: 22738.2500\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 28564.3281 - val_loss: 22638.5840\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 28431.4121 - val_loss: 22538.9160\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 28298.4980 - val_loss: 22439.2500\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 28165.5781 - val_loss: 22339.5840\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 28032.6621 - val_loss: 22239.9160\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 27899.7441 - val_loss: 22140.2500\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 27766.8281 - val_loss: 22040.5840\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 27633.9141 - val_loss: 21940.9160\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 27500.9980 - val_loss: 21841.2480\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 27368.0781 - val_loss: 21741.5820\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 27235.1621 - val_loss: 21641.9160\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 27102.2441 - val_loss: 21542.2480\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 26969.3301 - val_loss: 21442.5820\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 26836.4121 - val_loss: 21342.9160\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 26703.4941 - val_loss: 21243.2480\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 26570.5781 - val_loss: 21143.5820\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 26437.6621 - val_loss: 21043.9160\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 26304.7441 - val_loss: 20944.2480\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 26171.8281 - val_loss: 20844.5820\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 26038.9121 - val_loss: 20744.9160\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 25905.9941 - val_loss: 20645.2480\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 25773.0781 - val_loss: 20545.5820\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 25640.1621 - val_loss: 20445.9160\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 25507.2441 - val_loss: 20346.2480\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 25374.3301 - val_loss: 20246.5820\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 25241.4121 - val_loss: 20146.9160\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 25108.4941 - val_loss: 20047.2480\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 24975.5781 - val_loss: 19947.5820\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 24842.6621 - val_loss: 19847.9160\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 24709.7480 - val_loss: 19748.2480\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 24576.8281 - val_loss: 19648.5820\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 24443.9121 - val_loss: 19548.9160\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 24310.9941 - val_loss: 19449.2480\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 24178.0781 - val_loss: 19349.5820\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 24045.1641 - val_loss: 19249.9160\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 23912.2441 - val_loss: 19150.2480\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 23779.3281 - val_loss: 19050.5820\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 23646.4141 - val_loss: 18950.9160\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 23513.4941 - val_loss: 18851.2480\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 23380.5781 - val_loss: 18751.5820\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 23247.6621 - val_loss: 18651.9160\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 23114.7441 - val_loss: 18552.2480\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 22981.8301 - val_loss: 18452.5820\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 22848.9121 - val_loss: 18352.9160\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 22715.9941 - val_loss: 18253.2480\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 22583.0781 - val_loss: 18153.5820\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 22450.1621 - val_loss: 18053.9160\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 22317.2441 - val_loss: 17954.2480\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 22184.3281 - val_loss: 17854.5820\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 22051.4121 - val_loss: 17754.9160\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 21918.4941 - val_loss: 17655.2480\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 21785.5801 - val_loss: 17555.5820\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 21652.6621 - val_loss: 17455.9160\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 21519.7461 - val_loss: 17356.2480\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 21386.8301 - val_loss: 17256.5820\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 21253.9121 - val_loss: 17156.9160\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 21120.9961 - val_loss: 17057.2480\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 20988.0801 - val_loss: 16957.5820\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 20855.1641 - val_loss: 16857.9160\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 20722.2461 - val_loss: 16758.2480\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 20589.3301 - val_loss: 16658.5820\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 20456.4121 - val_loss: 16558.9160\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 20323.4961 - val_loss: 16459.2480\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 20190.5801 - val_loss: 16359.5820\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 20057.6621 - val_loss: 16259.9150\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19924.7461 - val_loss: 16160.2490\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 19791.8301 - val_loss: 16060.5820\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 19658.9121 - val_loss: 15960.9150\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 19525.9961 - val_loss: 15861.2490\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19393.0801 - val_loss: 15761.5820\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19260.1621 - val_loss: 15661.9150\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19127.2441 - val_loss: 15562.2490\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18994.3301 - val_loss: 15462.5820\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 18861.4141 - val_loss: 15362.9150\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18728.4961 - val_loss: 15263.2490\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 18595.5781 - val_loss: 15163.5811\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 18462.6621 - val_loss: 15063.9141\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18329.7461 - val_loss: 14964.2471\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18196.8301 - val_loss: 14864.5811\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18063.9121 - val_loss: 14764.9141\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17930.9961 - val_loss: 14665.2471\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 17798.0801 - val_loss: 14565.5811\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17665.1621 - val_loss: 14465.9141\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17532.2461 - val_loss: 14366.2471\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17399.3301 - val_loss: 14266.5811\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17266.4141 - val_loss: 14166.9141\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17133.4961 - val_loss: 14067.2471\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17000.5781 - val_loss: 13967.5811\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 16867.6621 - val_loss: 13867.9141\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 16734.7461 - val_loss: 13768.2490\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16601.8281 - val_loss: 13668.5820\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16468.9121 - val_loss: 13568.9150\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16335.9971 - val_loss: 13469.2490\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 16203.0791 - val_loss: 13369.5820\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16070.1631 - val_loss: 13269.9150\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 15937.2461 - val_loss: 13170.2490\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15804.3291 - val_loss: 13070.5820\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15671.4131 - val_loss: 12970.9150\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15538.4961 - val_loss: 12871.2490\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 15405.5791 - val_loss: 12771.5820\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 15272.6611 - val_loss: 12671.9150\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 15139.7451 - val_loss: 12572.2490\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15006.8291 - val_loss: 12472.5820\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14873.9111 - val_loss: 12372.9150\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 14740.9961 - val_loss: 12273.2490\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14608.0791 - val_loss: 12173.5820\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 14475.1631 - val_loss: 12073.9150\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14342.2451 - val_loss: 11974.2490\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14209.3281 - val_loss: 11874.5820\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14076.4141 - val_loss: 11774.9150\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13943.4961 - val_loss: 11675.2490\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13810.5781 - val_loss: 11575.5820\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13677.6641 - val_loss: 11475.9150\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13544.7451 - val_loss: 11376.2490\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13411.8281 - val_loss: 11276.5820\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 13278.9111 - val_loss: 11176.9150\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13145.9961 - val_loss: 11077.2490\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13013.0791 - val_loss: 10977.5820\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12880.1631 - val_loss: 10877.9150\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12747.2461 - val_loss: 10778.2490\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 12614.3291 - val_loss: 10678.5820\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12481.4131 - val_loss: 10578.9150\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12348.4961 - val_loss: 10479.2490\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12215.5791 - val_loss: 10379.5820\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12082.6631 - val_loss: 10279.9150\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11949.7461 - val_loss: 10180.2490\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11816.8291 - val_loss: 10080.5820\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11683.9131 - val_loss: 9980.9150\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11550.9961 - val_loss: 9881.2480\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11418.0791 - val_loss: 9781.5811\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11285.1611 - val_loss: 9681.9150\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11152.2461 - val_loss: 9582.2480\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11019.3281 - val_loss: 9482.5811\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 10886.4131 - val_loss: 9382.9150\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 10753.4961 - val_loss: 9283.2480\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10620.5791 - val_loss: 9183.5811\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 10487.6631 - val_loss: 9083.9150\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10354.7461 - val_loss: 8984.2480\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10221.8291 - val_loss: 8884.5811\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 10088.9131 - val_loss: 8784.9150\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 9955.9961 - val_loss: 8685.2480\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9823.0791 - val_loss: 8585.5811\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9690.1631 - val_loss: 8485.9150\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9557.5068 - val_loss: 8387.4463\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 9442.6787 - val_loss: 8290.0537\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 9329.3154 - val_loss: 8195.0010\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 9236.7822 - val_loss: 8102.0566\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 9154.6826 - val_loss: 8012.2837\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 9083.1904 - val_loss: 7925.3599\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9013.9834 - val_loss: 7841.0083\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8946.8330 - val_loss: 7758.9575\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8881.5303 - val_loss: 7678.9800\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8817.8867 - val_loss: 7600.8687\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8755.7373 - val_loss: 7524.4263\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8694.9287 - val_loss: 7449.4868\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8635.3213 - val_loss: 7375.8989\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8576.7979 - val_loss: 7303.5215\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8519.2432 - val_loss: 7232.2271\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8462.5566 - val_loss: 7161.9062\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8406.6514 - val_loss: 7092.4614\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8361.6807 - val_loss: 7025.9517\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8327.8037 - val_loss: 6962.0820\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8295.2490 - val_loss: 6900.5903\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8263.8838 - val_loss: 6841.2329\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8233.5889 - val_loss: 6783.7983\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8204.2539 - val_loss: 6728.0923\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8175.7852 - val_loss: 6673.9375\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8148.0923 - val_loss: 6621.1743\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 8121.0957 - val_loss: 6569.6641\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8094.7251 - val_loss: 6519.2817\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8068.9219 - val_loss: 6469.9082\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8043.6196 - val_loss: 6421.4370\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8018.7715 - val_loss: 6373.7793\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7994.3306 - val_loss: 6326.8521\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7970.2544 - val_loss: 6280.5757\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7946.5034 - val_loss: 6234.8853\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7923.0449 - val_loss: 6189.7153\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7899.8491 - val_loss: 6145.0156\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7876.8843 - val_loss: 6100.7300\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7854.1284 - val_loss: 6056.8130\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7831.5586 - val_loss: 6013.2319\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7809.1538 - val_loss: 5969.9453\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7786.8970 - val_loss: 5926.9199\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7764.7715 - val_loss: 5884.1294\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7742.7632 - val_loss: 5841.5425\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7720.8569 - val_loss: 5799.1353\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7699.0376 - val_loss: 5756.8872\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7677.2993 - val_loss: 5714.7827\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7656.0410 - val_loss: 5673.5190\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7638.5547 - val_loss: 5633.0117\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7621.3862 - val_loss: 5593.1836\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7604.4956 - val_loss: 5553.9663\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7587.8608 - val_loss: 5515.2930\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7571.4526 - val_loss: 5482.9995\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7558.7915 - val_loss: 5458.7598\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7549.2632 - val_loss: 5435.5874\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7540.0991 - val_loss: 5413.3726\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7531.2603 - val_loss: 5392.0181\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7522.7163 - val_loss: 5371.4375\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7515.6284 - val_loss: 5352.0078\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7510.2324 - val_loss: 5333.6167\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7505.0728 - val_loss: 5316.1562\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7500.1235 - val_loss: 5299.5352\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7495.3618 - val_loss: 5283.6660\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7490.7715 - val_loss: 5268.4800\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7486.3354 - val_loss: 5253.9004\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7482.0347 - val_loss: 5239.8750\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7477.8594 - val_loss: 5226.3403\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7473.7954 - val_loss: 5213.2505\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7469.8306 - val_loss: 5200.5610\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7465.9546 - val_loss: 5188.2300\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7462.1602 - val_loss: 5176.2241\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7458.4380 - val_loss: 5164.5054\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7454.7808 - val_loss: 5153.0488\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7451.1821 - val_loss: 5141.8247\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7447.6353 - val_loss: 5130.8101\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7444.1328 - val_loss: 5119.9829\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7440.6743 - val_loss: 5109.3208\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7437.2524 - val_loss: 5098.8149\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7433.8638 - val_loss: 5088.4429\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7430.5044 - val_loss: 5078.1870\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7427.1724 - val_loss: 5068.0415\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7423.8633 - val_loss: 5057.9917\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7420.5742 - val_loss: 5048.0288\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7417.3042 - val_loss: 5038.1392\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7414.0508 - val_loss: 5028.3218\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7410.8120 - val_loss: 5018.5620\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7407.5864 - val_loss: 5008.8555\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7404.3711 - val_loss: 4999.1987\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7401.1655 - val_loss: 4989.5820\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7397.9692 - val_loss: 4980.0005\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7394.7793 - val_loss: 4970.4531\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7391.5962 - val_loss: 4960.9321\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7389.1548 - val_loss: 4952.3013\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7387.8237 - val_loss: 4944.4683\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7386.4556 - val_loss: 4937.3599\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7385.0527 - val_loss: 4930.8979\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7383.6211 - val_loss: 4925.0220\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7382.1616 - val_loss: 4919.6753\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7380.6782 - val_loss: 4914.8032\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7379.1719 - val_loss: 4910.3608\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7377.6460 - val_loss: 4906.3042\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7376.1016 - val_loss: 4902.5942\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7374.5410 - val_loss: 4899.1978\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7372.9634 - val_loss: 4896.0845\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7371.3726 - val_loss: 4893.2246\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7369.7690 - val_loss: 4890.5933\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7368.1538 - val_loss: 4888.1665\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7366.5273 - val_loss: 4885.9263\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7364.8906 - val_loss: 4883.8550\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7363.2456 - val_loss: 4881.9336\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7361.5933 - val_loss: 4880.1484\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7359.9312 - val_loss: 4878.4858\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7358.2642 - val_loss: 4876.9316\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7356.5898 - val_loss: 4875.4780\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7354.9102 - val_loss: 4874.1147\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7353.2241 - val_loss: 4872.8320\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7351.5312 - val_loss: 4871.6211\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7349.8354 - val_loss: 4870.4746\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7348.1353 - val_loss: 4869.3867\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7346.4316 - val_loss: 4868.3496\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7344.7212 - val_loss: 4867.3618\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7343.0093 - val_loss: 4866.4194\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7341.2915 - val_loss: 4865.5156\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7339.5723 - val_loss: 4864.6450\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7337.8501 - val_loss: 4863.8052\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7336.1235 - val_loss: 4862.9937\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7334.3940 - val_loss: 4862.2085\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7332.6626 - val_loss: 4861.4438\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7330.9277 - val_loss: 4860.7012\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7329.1914 - val_loss: 4859.9771\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7327.4512 - val_loss: 4859.2710\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7325.7095 - val_loss: 4858.5806\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7323.9644 - val_loss: 4857.9009\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7322.2183 - val_loss: 4857.2329\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7320.4688 - val_loss: 4856.5767\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7318.7188 - val_loss: 4855.9302\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7316.9644 - val_loss: 4855.2915\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7315.2095 - val_loss: 4854.6626\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7313.4517 - val_loss: 4854.0410\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7311.6919 - val_loss: 4853.4238\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7309.9312 - val_loss: 4852.8140\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7308.1680 - val_loss: 4852.2065\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7306.4019 - val_loss: 4851.6055\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7304.6343 - val_loss: 4851.0093\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7302.8672 - val_loss: 4850.4160\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7301.0952 - val_loss: 4849.8247\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7299.4038 - val_loss: 4848.3237\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7297.8398 - val_loss: 4846.0015\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7296.1040 - val_loss: 4842.9360\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7294.2212 - val_loss: 4840.1177\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7292.5415 - val_loss: 4837.5239\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7290.8516 - val_loss: 4835.1309\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7289.1484 - val_loss: 4832.9204\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7287.4390 - val_loss: 4830.8745\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7285.7163 - val_loss: 4828.9722\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7283.9863 - val_loss: 4827.2046\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7282.2495 - val_loss: 4825.5566\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7280.5210 - val_loss: 4823.0923\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7278.7969 - val_loss: 4820.8140\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7277.0776 - val_loss: 4818.7070\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7275.3491 - val_loss: 4816.7515\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7273.6226 - val_loss: 4814.0059\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7271.9087 - val_loss: 4811.4800\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7270.1938 - val_loss: 4809.1470\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7268.4702 - val_loss: 4806.9883\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7266.7344 - val_loss: 4804.9917\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7264.9902 - val_loss: 4803.1309\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7263.2397 - val_loss: 4801.3999\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7261.5195 - val_loss: 4798.8501\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7259.7563 - val_loss: 4796.4956\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7258.0239 - val_loss: 4794.3218\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7256.2798 - val_loss: 4792.3032\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7254.5273 - val_loss: 4790.4341\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7252.8384 - val_loss: 4787.7515\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7251.0405 - val_loss: 4785.2798\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7249.3032 - val_loss: 4782.9941\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7247.5562 - val_loss: 4780.8813\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7245.7993 - val_loss: 4778.9219\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7244.0347 - val_loss: 4777.1001\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7242.3477 - val_loss: 4774.4565\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7240.5234 - val_loss: 4772.0195\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7238.7749 - val_loss: 4769.7690\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7237.0156 - val_loss: 4767.6821\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7235.2485 - val_loss: 4765.7505\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7233.5239 - val_loss: 4763.0015\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7231.7310 - val_loss: 4760.4707\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7229.9780 - val_loss: 4758.1313\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7228.2148 - val_loss: 4755.9712\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7226.4414 - val_loss: 4753.9673\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7224.6587 - val_loss: 4752.1069\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7222.8921 - val_loss: 4749.4180\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7221.1172 - val_loss: 4746.9380\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7219.3516 - val_loss: 4744.6470\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7217.5762 - val_loss: 4742.5298\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7215.7915 - val_loss: 4740.5664\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7213.9980 - val_loss: 4738.7388\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7212.2749 - val_loss: 4736.0767\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7210.4312 - val_loss: 4733.6196\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7208.6548 - val_loss: 4731.3501\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7206.8687 - val_loss: 4729.2505\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7205.0737 - val_loss: 4727.3022\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7203.3345 - val_loss: 4724.5249\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7201.5015 - val_loss: 4721.9653\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7199.7212 - val_loss: 4719.6016\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7197.9922 - val_loss: 4717.9321\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7196.4048 - val_loss: 4716.8911\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7195.0337 - val_loss: 4715.4438\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7193.6484 - val_loss: 4713.6274\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7192.2446 - val_loss: 4711.4868\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7190.8267 - val_loss: 4709.0444\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7189.3970 - val_loss: 4706.3306\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7187.9536 - val_loss: 4703.3794\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7186.5005 - val_loss: 4700.2065\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7185.1836 - val_loss: 4697.8164\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7183.8726 - val_loss: 4696.1226\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7182.4517 - val_loss: 4695.0640\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7181.0444 - val_loss: 4693.5972\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7179.7461 - val_loss: 4691.7617\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7178.4204 - val_loss: 4689.5923\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7177.0718 - val_loss: 4687.1226\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7175.7017 - val_loss: 4684.3853\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7174.3359 - val_loss: 4682.3843\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7173.0073 - val_loss: 4681.0508\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7171.7163 - val_loss: 4679.3335\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7170.4175 - val_loss: 4677.2695\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7169.0913 - val_loss: 4674.8911\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7167.7422 - val_loss: 4672.2310\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7166.4272 - val_loss: 4670.3062\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7165.0981 - val_loss: 4669.0415\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7163.8008 - val_loss: 4667.3853\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7162.5132 - val_loss: 4665.3730\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7161.1968 - val_loss: 4663.0366\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7159.8540 - val_loss: 4660.4126\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7158.5063 - val_loss: 4658.5220\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7157.1797 - val_loss: 4656.2974\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7155.9019 - val_loss: 4654.7661\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7154.5688 - val_loss: 4652.8638\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7153.2617 - val_loss: 4650.6309\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7151.9258 - val_loss: 4648.0918\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7150.6797 - val_loss: 4646.2827\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7149.3320 - val_loss: 4645.1265\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7148.0156 - val_loss: 4643.5620\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7146.7339 - val_loss: 4641.6265\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7145.4199 - val_loss: 4639.3540\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7144.0776 - val_loss: 4636.7837\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7142.7104 - val_loss: 4633.9419\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7141.4766 - val_loss: 4631.8608\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7140.1680 - val_loss: 4630.4648\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7138.7417 - val_loss: 4629.6890\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7137.4976 - val_loss: 4628.4614\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7136.2363 - val_loss: 4626.8257\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7134.9414 - val_loss: 4624.8218\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7133.6172 - val_loss: 4622.4863\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7132.2617 - val_loss: 4619.8530\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7130.8823 - val_loss: 4616.9512\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7129.4805 - val_loss: 4613.8003\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7128.2266 - val_loss: 4611.4507\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7126.9526 - val_loss: 4609.8184\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7125.5547 - val_loss: 4608.8306\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7124.1484 - val_loss: 4607.4067\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7122.8647 - val_loss: 4605.5903\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7121.5454 - val_loss: 4603.4214\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7120.1968 - val_loss: 4600.9331\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7118.8203 - val_loss: 4598.1567\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7117.4546 - val_loss: 4596.1392\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7116.1128 - val_loss: 4594.8159\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7114.7988 - val_loss: 4593.0840\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7113.4824 - val_loss: 4590.9878\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7112.1343 - val_loss: 4588.5605\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7110.7573 - val_loss: 4585.8379\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7109.4194 - val_loss: 4583.8765\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7108.0586 - val_loss: 4582.5991\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7106.7305 - val_loss: 4580.9087\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7105.4106 - val_loss: 4578.8477\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7104.0610 - val_loss: 4576.4478\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7102.6802 - val_loss: 4573.7476\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7101.2944 - val_loss: 4571.8066\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7099.9312 - val_loss: 4569.5190\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7098.6079 - val_loss: 4567.9517\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7097.2407 - val_loss: 4565.9956\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7095.8931 - val_loss: 4563.6909\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7094.5142 - val_loss: 4561.0718\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7093.2183 - val_loss: 4559.2056\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7091.8242 - val_loss: 4558.0234\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7090.4790 - val_loss: 4556.4126\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7089.1528 - val_loss: 4554.4185\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7087.7949 - val_loss: 4552.0757\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7086.4082 - val_loss: 4549.4175\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7084.9937 - val_loss: 4546.4780\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7083.6978 - val_loss: 4544.3286\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7082.3423 - val_loss: 4542.8926\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7080.8652 - val_loss: 4541.5762\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7079.5571 - val_loss: 4539.8379\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7078.2144 - val_loss: 4537.7271\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7076.8394 - val_loss: 4535.2734\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7075.4351 - val_loss: 4532.5161\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7074.0039 - val_loss: 4529.4785\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7072.7876 - val_loss: 4527.2466\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7071.4370 - val_loss: 4525.7383\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7069.9595 - val_loss: 4524.8843\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7068.5547 - val_loss: 4523.5640\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7067.2383 - val_loss: 4521.8208\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7065.8853 - val_loss: 4519.6973\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7064.5015 - val_loss: 4517.2339\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7063.0879 - val_loss: 4514.4585\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7061.6465 - val_loss: 4511.4038\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7060.2261 - val_loss: 4509.1602\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7058.8647 - val_loss: 4507.6460\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7057.4438 - val_loss: 4505.7261\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7056.0703 - val_loss: 4503.4395\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7054.6646 - val_loss: 4500.8257\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7053.2910 - val_loss: 4498.9780\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7051.8599 - val_loss: 4496.7578\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7050.4780 - val_loss: 4495.2690\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7049.1147 - val_loss: 4493.3687\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7047.7358 - val_loss: 4491.0957\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7046.3262 - val_loss: 4488.4907\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7044.8892 - val_loss: 4485.5806\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7043.5942 - val_loss: 4483.4771\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7042.1914 - val_loss: 4482.0913\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7040.6851 - val_loss: 4480.2852\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7039.3071 - val_loss: 4478.0938\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7037.8989 - val_loss: 4475.5591\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7036.4785 - val_loss: 4473.7896\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7035.0835 - val_loss: 4471.6333\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7033.6743 - val_loss: 4469.1270\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7032.2617 - val_loss: 4467.3848\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7030.8579 - val_loss: 4465.2534\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7029.4487 - val_loss: 4462.7651\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7028.0220 - val_loss: 4461.0454\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7026.6294 - val_loss: 4458.9297\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7025.2188 - val_loss: 4456.4565\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7023.7773 - val_loss: 4453.6616\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7022.4556 - val_loss: 4451.6636\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7021.0122 - val_loss: 4450.3853\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7019.5547 - val_loss: 4448.6660\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7018.1704 - val_loss: 4446.5464\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7016.7524 - val_loss: 4444.0698\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7015.3062 - val_loss: 4441.2695\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7013.8462 - val_loss: 4439.2710\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7012.4175 - val_loss: 4436.8984\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7011.0059 - val_loss: 4435.2852\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7009.5952 - val_loss: 4433.2603\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7008.1777 - val_loss: 4430.8657\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7006.7305 - val_loss: 4428.1353\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7005.3140 - val_loss: 4426.2012\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7003.8433 - val_loss: 4424.4355\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7002.4438 - val_loss: 4422.2715\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7001.0117 - val_loss: 4419.7476\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6999.5483 - val_loss: 4416.8989\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6998.2129 - val_loss: 4414.8613\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6996.7539 - val_loss: 4413.5566\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6995.2671 - val_loss: 4411.8047\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6993.8633 - val_loss: 4409.6484\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6992.4272 - val_loss: 4407.1313\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6990.9570 - val_loss: 4404.2847\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6989.4980 - val_loss: 4402.2515\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6988.0312 - val_loss: 4399.8423\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6986.6226 - val_loss: 4398.2017\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6985.1675 - val_loss: 4396.1479\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6983.7329 - val_loss: 4393.7173\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6982.2656 - val_loss: 4390.9492\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6980.8555 - val_loss: 4388.9897\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6979.3657 - val_loss: 4387.7563\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6977.9668 - val_loss: 4386.0649\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6976.5566 - val_loss: 4383.9595\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6975.1113 - val_loss: 4381.4800\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6973.6343 - val_loss: 4378.6641\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6972.1304 - val_loss: 4375.5488\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6970.6821 - val_loss: 4373.2734\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6969.2358 - val_loss: 4371.7622\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6967.7324 - val_loss: 4369.8179\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6966.2969 - val_loss: 4367.4800\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6964.8247 - val_loss: 4364.7891\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6963.3306 - val_loss: 4362.9043\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6961.8867 - val_loss: 4360.6196\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6960.4175 - val_loss: 4357.9731\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6958.9653 - val_loss: 4356.1348\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6957.4805 - val_loss: 4353.8867\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6956.0132 - val_loss: 4351.2769\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6954.5664 - val_loss: 4349.4663\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6953.0762 - val_loss: 4347.2461\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6951.6055 - val_loss: 4344.6577\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6950.1401 - val_loss: 4342.8687\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6948.6665 - val_loss: 4340.6675\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6947.1948 - val_loss: 4338.0957\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6945.6938 - val_loss: 4336.3198\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6944.2534 - val_loss: 4334.1294\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6942.7788 - val_loss: 4331.5645\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6941.2734 - val_loss: 4328.6602\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6939.8618 - val_loss: 4326.5923\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6938.3491 - val_loss: 4325.2773\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6936.8667 - val_loss: 4323.4976\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6935.4204 - val_loss: 4321.3013\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6933.9414 - val_loss: 4318.7280\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6932.4292 - val_loss: 4315.8125\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6930.8882 - val_loss: 4312.5933\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6929.5259 - val_loss: 4310.2437\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6928.0522 - val_loss: 4308.6758\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6926.4434 - val_loss: 4307.8159\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6925.0137 - val_loss: 4306.4448\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6923.5938 - val_loss: 4304.6079\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6922.1353 - val_loss: 4302.3550\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6920.6421 - val_loss: 4299.7280\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6919.1172 - val_loss: 4296.7612\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6917.5625 - val_loss: 4293.4902\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6915.9819 - val_loss: 4289.9434\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6914.5859 - val_loss: 4287.3027\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6913.1484 - val_loss: 4285.4790\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6911.5703 - val_loss: 4284.3911\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6909.9785 - val_loss: 4282.8086\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6908.5317 - val_loss: 4280.7827\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6907.0483 - val_loss: 4278.3530\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6905.5298 - val_loss: 4275.5605\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6903.9824 - val_loss: 4272.4414\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6902.4282 - val_loss: 4270.1909\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6900.9126 - val_loss: 4268.7212\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6899.4556 - val_loss: 4266.7935\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6897.9741 - val_loss: 4264.4517\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6896.4570 - val_loss: 4261.7349\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6894.9102 - val_loss: 4258.6812\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6893.3589 - val_loss: 4256.4961\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6891.8242 - val_loss: 4253.9146\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6890.3555 - val_loss: 4252.1548\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6888.8105 - val_loss: 4249.9595\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6887.2993 - val_loss: 4247.3735\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6885.7578 - val_loss: 4244.4355\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6884.3228 - val_loss: 4242.3530\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6882.7603 - val_loss: 4241.0435\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6881.2368 - val_loss: 4239.2500\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6879.7539 - val_loss: 4237.0229\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6878.2363 - val_loss: 4234.4067\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6876.6836 - val_loss: 4231.4380\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6875.1021 - val_loss: 4228.1509\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6873.6577 - val_loss: 4225.7573\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6872.1392 - val_loss: 4224.1699\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6870.4849 - val_loss: 4222.1270\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6868.9751 - val_loss: 4219.6704\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6867.4312 - val_loss: 4216.8442\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6865.9438 - val_loss: 4214.8667\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6864.3491 - val_loss: 4212.4746\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6862.8218 - val_loss: 4210.8862\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6861.3281 - val_loss: 4208.8398\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6859.8120 - val_loss: 4206.3774\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6858.2617 - val_loss: 4203.5454\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6856.6782 - val_loss: 4200.3735\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6855.1929 - val_loss: 4198.0898\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6853.6382 - val_loss: 4196.6094\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6852.0532 - val_loss: 4194.6562\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6850.5405 - val_loss: 4192.2739\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6848.9897 - val_loss: 4189.5117\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6847.4062 - val_loss: 4186.4004\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6845.8979 - val_loss: 4184.1743\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6844.3257 - val_loss: 4182.7485\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6842.7798 - val_loss: 4180.8394\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6841.2632 - val_loss: 4178.4980\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6839.7090 - val_loss: 4175.7642\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6838.1235 - val_loss: 4172.6802\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6836.5093 - val_loss: 4170.4785\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6834.9648 - val_loss: 4167.8726\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6833.4082 - val_loss: 4166.1069\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6831.8745 - val_loss: 4163.8906\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6830.3262 - val_loss: 4161.2676\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6828.7441 - val_loss: 4158.2759\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6827.1870 - val_loss: 4156.1675\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6825.5864 - val_loss: 4153.6406\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6824.0415 - val_loss: 4151.9448\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6822.4995 - val_loss: 4149.7925\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6820.9507 - val_loss: 4147.2231\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6819.3657 - val_loss: 4144.2793\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6817.7495 - val_loss: 4141.0005\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6816.3296 - val_loss: 4138.6328\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6814.7559 - val_loss: 4137.0835\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6813.0391 - val_loss: 4136.2759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5a3d9b8c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zzENQgeskZj_",
        "outputId": "61489b74-d75f-4d23-e162-ffde0e6e4ca9"
      },
      "source": [
        "y_pred = model.predict(x_val)\n",
        "\n",
        "plt.scatter(x_val, y_val)\n",
        "plt.scatter(x_val, y_pred, color='r')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhTuU1SYl-PE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}